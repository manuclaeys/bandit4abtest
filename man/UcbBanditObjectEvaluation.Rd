% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/UCB_bandit_object_evaluation.R
\name{UcbBanditObjectEvaluation}
\alias{UcbBanditObjectEvaluation}
\title{UcbBanditObjectEvaluation}
\usage{
UcbBanditObjectEvaluation(
  visitor_reward = visitor_reward,
  K = ncol(visitor_reward),
  alpha = 1,
  average = FALSE,
  IsRewardAreBoolean = FALSE,
  dt.reward = NA,
  explanatory_variable = colnames(dt.reward)
)
}
\arguments{
\item{visitor_reward}{Dataframe of integer or numeric values}

\item{K}{Integer value (optional)}

\item{alpha}{Numeric value (optional)}

\item{average}{Boolean values to define the cumulative regret evaluation (simple:FALSE, average:TRUE)}
}
\value{
\itemize{ List of element:
 \item ucb_alloc: ucb object ,
 \item cum_reg_ucb_alloc: List numeric.
 }
}
\description{
Run the UCB algorithm using visitor_reward values with \code{\link{UCB}} function.
Stop if something is wrong.
After execution of UCB, calculates the cumulative regret
associated with the choices made.
Review the cumulative regret according iterations and an ucb object.
See also \code{\link{UCB}}, \code{\link{CumulativeRegret}}
Require \code{\link{tic}} and \code{\link{toc}} from \code{\link{tictoc}} library
}
\examples{
## Generates 1000 numbers from 2 binomial distributions
set.seed(4434)
K1 <- rbinom(1000, 1, 0.6)
K2 <- rbinom(1000, 1, 0.7)
## Define a dataframe of rewards
visitor_reward <- as.data.frame(cbind(K1,K2) )
#Run UCB algorithm with policy evaluation
UcbBanditObjectEvaluation(visitor_reward,alpha = 1)
UcbBanditObjectEvaluation(visitor_reward,alpha = 1,average = TRUE,IsRewardAreBoolean = TRUE)
}
