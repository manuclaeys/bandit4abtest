% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/uniform_bandit_object_evaluation.R
\name{uniform_bandit_object_evaluation}
\alias{uniform_bandit_object_evaluation}
\title{uniform_bandit_object_evaluation}
\usage{
uniform_bandit_object_evaluation(
  visitor_reward = visitor_reward,
  K = ncol(visitor_reward),
  average = FALSE,
  IsRewardAreBoolean = FALSE,
  dt.reward = NA,
  explanatory_variable = colnames(dt.reward)
)
}
\arguments{
\item{visitor_reward}{Dataframe of integer or numeric values}

\item{K}{Integer value (optional)}
}
\value{
\itemize{ List of element:
 \item uniform_bandit_alloc: UniformBandit object ,
 \item cum_reg_uniform_bandit_alloc: List numeric.
 }
}
\description{
Run a uniform allocation using visitor_reward values with \code{\link{UniformBandit}} function.
Stop if something is wrong.
After execution of UniformBandit, calculates the cumulative regret
associated with the choices made.
Review the cumulative regret according iterations and an UniformBandit object.
See also \code{\link{UniformBandit}}, \code{\link{CumulativeRegret}}
Require \code{\link{tic}} and \code{\link{toc}} from \code{\link{tictoc}} library
}
\examples{
## Generates 1000 numbers from 2 binomial distributions
set.seed(4434)
K1 <- rbinom(1000, 1, 0.6)
K2 <- rbinom(1000, 1, 0.7)
## Define a dataframe of rewards
visitor_reward <- as.data.frame(cbind(K1,K2) )
#Run uniform bandit allocation with policy evaluation
uniform_bandit_object_evaluation(visitor_reward)
uniform_bandit_object_evaluation(visitor_reward,average = TRUE,IsRewardAreBoolean = TRUE)

}
