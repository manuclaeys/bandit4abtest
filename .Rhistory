comp_reward <- data.frame(cbind(my_ctree_ucb.reward_moyenne,
my_linucb_ucb.reward_moyenne,
my_ctree_ucb.reward_clust,
my_linucb_ucb.reward_clust,
unif_alloc.reward))
ggplot(comp_reward, aes(c(1:nrow(comp_reward)), y = value, color = Algorithm)) +
geom_line(linetype="dashed",aes(y = my_ctree_ucb.reward_clust, col = "DBACtreeucb"),size = 0.5) +
geom_line(linetype="dashed",aes(y = my_linucb_ucb.reward_clust, col = "DBALinucb"),size = 0.5) +
geom_line(linetype="dashed",aes(y = my_linucb_ucb.reward_moyenne, col = "LinUCB"),size = 1) +
geom_line(linetype="dashed",aes(y = my_ctree_ucb.reward_moyenne, col = "Ctreeucb"),size = 0.5) +
geom_line(linetype="dashed",aes(y = unif_alloc.reward, col = "Uniform"),size = 0.5) +
scale_colour_manual(values =  c("DBACtreeucb"="brown","DBALinucb"="blue","LinUCB"="red","Ctreeucb"="green","Uniform"="black"))+
xlab("Time") +
ylab("Reward")
max(my_linucb_ucb.reward_clust)
max(my_linucb_ucb.reward_clust)/length(my_linucb_ucb.reward_clust)
rm(list=ls())
###Algo 1
#fichier <- "cheville_droite_partialDBA191819"
fichier <- "cheville_droiteDBA191819"
learn=0.5
arm_for_learn = 1
##Chargement du fichier
#please set the directory to this file location
setwd("~/Documents/manue/Manipulation/datascience-emmanuelle/programme_R/serveur_cluster_these/cluster") # the following line is for getting the path of your current open file
current_path <-  getwd()
#source(paste(current_path,'/install_package.R',sep=""))
source(paste(current_path,'/Formating data/R/transform_categorial_to_binary.R',sep=""))
##Définition des variables explicatives
###Data format###
library(jsonlite)
setwd("~/Documents/manue/Manipulation/datascience-emmanuelle/programme_R/serveur_cluster_these/cluster")
df  =  jsonlite::fromJSON(paste(fichier,".JSON",sep=""), simplifyDataFrame = TRUE)  # read text file
#df <-  df [1:10000,]
##A finir
listCategorial =c("clusterV5","clusterV6","clusterV7")
listInteger  = c()
visitorReward <- as.data.frame(transform_categorial_to_binary( listCategorial = c("etat"), dt=df))
for(i in 1:ncol(visitorReward)) visitorReward[,i] <- as.integer(visitorReward[,i])
###
dt <- df[, c(listCategorial,listInteger)]
##Définition des variable explicables
## Algo
##
###File path
(WD <- getwd())
WD <- paste(current_path , "/Bandit", sep = "")
if (!is.null(WD)) setwd(WD)
####CTREE UCB####
#source("R/ctree_object_evaluation.R")
library(bandit4abtest)
for(i in listCategorial) dt[,i] <-as.factor(as.character(dt[,i]))
#Do not multiply the dataset if Config 30_70
#Config 30_70
if(learn==0.3) learn_size = nrow(dt)*0.30
#multiply the dataset if Config 100_100
#Config 100_100
if(learn==0.5) {
learn_size = nrow(dt)
rep_data <- 2
dt <- dt[rep(1:nrow(dt),each=rep_data),]
visitorReward <- visitorReward[rep(1:nrow(visitorReward),each=rep_data),]
}
dt.old <- dt
set.seed(1234)
####CTREEUCBPARAMETER
## - the size of the learning set is a percent of the all dataset nrow(dt)*0.3 or nrow(dt)*0.5
#  - mincriterion parameter refers to 1 -risk error accepted  (0.99,0.95,0.90)
#  - alpha refers to the dynamic allocation parameter (U.C.B)
#  - arm_for_learn is the original varitation (names(visitorReward)[1] or names(visitorReward)[2] ...or  names(visitorReward)[5] )
#  testtype and teststat is refer to type of test to build the tree (see the paper for more details)
# and are not supposed to be modified#
ctreeucb_parameters_control <- ctreeucb_parameters_control_default(dt = dt.old,
visitorReward ,
learn_size = learn_size,
alpha =1,
arm_for_learn = names(visitorReward)[arm_for_learn],
is_reward_are_boolean = TRUE,
ctree_control_val=ctree_control(
mincriterion = 0.95,
testtype = "Bonferroni",
teststat = "quadratic",
splitstat = c( "quadratic"))
)
my_ctree_ucb <- ctreeucbBanditObjectEvaluation(dt= dt.old,visitor_reward=visitorReward, ctree_parameters_control= ctreeucb_parameters_control, average = TRUE)
max(my_ctree_ucb$cum_reg_ctree)
max(my_ctree_ucb$cum_reg_ctree)
###END CTREE UCB###
# transform_categorial_to_binary bug et ca fait chier
dt   <- transform_categorial_to_binary(listCategorial = listCategorial, dt = dt)
dt     <- as.data.frame(dt)
first <- my_ctree_ucb$ctreeucb_bandit_alloc$first_train_element
last <- nrow(dt)
dt <- dt[first:last,]
dt.reward <- dt.old[first:last,]
visitorReward <- visitorReward[first:last,]
my_linucb_ucb <- LinucbBanditObjectEvaluation(dt=dt, visitor_reward=visitorReward, alpha= 1, average = TRUE, IsRewardAreBoolean = TRUE,dt.reward=dt.reward)
max(my_linucb_ucb$cum_reg_linucb)
### END Lin UCB ###
### PLOT  OF REWARD###
my_ctree_ucb.reward_clust <- reward_cumulative(my_ctree_ucb$ctreeucb_bandit_alloc$choice, visitor_reward = visitorReward)
max(my_ctree_ucb.reward_clust)
my_linucb_ucb.reward_clust <- reward_cumulative(my_linucb_ucb$linucb_bandit_alloc$choice, visitor_reward = visitorReward)
max(my_linucb_ucb.reward_clust)
#####################################################################################
################ Moyenne
#####################################################################
######################################################################
###################### A/B Test ########################
rm(list=setdiff(ls(), c("my_ctree_ucb.reward_clust","data.train","my_linucb_ucb.reward_clust","K","fichier","learn","arm_for_learn")))
setwd("~/Documents/manue/Manipulation/datascience-emmanuelle/programme_R/serveur_cluster_these/cluster")
df  =  jsonlite::fromJSON(paste(fichier,".JSON",sep=""), simplifyDataFrame = TRUE)  # read text file
#df <-  df [1:10000,]
##A finir
listCategorial =c()
listInteger  = c("moyenneV5","moyenneV6","moyenneV7")
visitorReward <- as.data.frame(transform_categorial_to_binary( listCategorial = c("etat"), dt=df))
for(i in 1:ncol(visitorReward)) visitorReward[,i] <- as.integer(visitorReward[,i])
###
dt <- df[, c(listInteger)]
##Définition des variable explicables
####CTREE UCB####
#source("R/ctree_object_evaluation.R")
library(bandit4abtest)
#Do not multiply the dataset if Config 30_70
#Config 30_70
if(learn==0.3) learn_size = nrow(dt)*0.30
#multiply the dataset if Config 100_100
#Config 100_100
if(learn==0.5) {
learn_size = nrow(dt)
rep_data <- 2
dt <- dt[rep(1:nrow(dt),each=rep_data),]
visitorReward <- visitorReward[rep(1:nrow(visitorReward),each=rep_data),]
}
dt.old <- dt
set.seed(1234)
####CTREEUCBPARAMETER
## - the size of the learning set is a percent of the all dataset nrow(dt)*0.3 or nrow(dt)*0.5
#  - mincriterion parameter refers to 1 -risk error accepted  (0.99,0.95,0.90)
#  - alpha refers to the dynamic allocation parameter (U.C.B)
#  - arm_for_learn is the original varitation (names(visitorReward)[1] or names(visitorReward)[2] ...or  names(visitorReward)[5] )
#  testtype and teststat is refer to type of test to build the tree (see the paper for more details)
# and are not supposed to be modified#
ctreeucb_parameters_control <- ctreeucb_parameters_control_default(dt = dt.old,
visitorReward ,
learn_size = learn_size,
alpha =1,
arm_for_learn = names(visitorReward)[arm_for_learn ],
is_reward_are_boolean = TRUE,
ctree_control_val=ctree_control(
mincriterion = 0.95,
testtype = "Bonferroni",
teststat = "quadratic",
splitstat = c( "quadratic"))
)
my_ctree_ucb <- ctreeucbBanditObjectEvaluation(dt= dt.old,visitor_reward=visitorReward, ctree_parameters_control= ctreeucb_parameters_control, average = TRUE)
max(my_ctree_ucb$cum_reg_ctree)
max(my_ctree_ucb$cum_reg_ctree)
###END CTREE UCB###
first <- my_ctree_ucb$ctreeucb_bandit_alloc$first_train_element
last <- nrow(dt)
dt <- dt[first:last,]
dt.reward <- dt.old[first:last,]
visitorReward <- visitorReward[first:last,]
my_linucb_ucb <- LinucbBanditObjectEvaluation(dt=dt, visitor_reward=visitorReward, alpha= 1, average = TRUE, IsRewardAreBoolean = TRUE,dt.reward=dt.reward)
max(my_linucb_ucb$cum_reg_linucb)
### END Lin UCB ###
### PLOT  OF REWARD###
my_ctree_ucb.reward_moyenne <- reward_cumulative(my_ctree_ucb$ctreeucb_bandit_alloc$choice, visitor_reward = visitorReward)
max(my_ctree_ucb.reward_moyenne)
my_linucb_ucb.reward_moyenne <- reward_cumulative(my_linucb_ucb$linucb_bandit_alloc$choice, visitor_reward = visitorReward)
max(my_linucb_ucb.reward_moyenne)
### Random ###
unif_alloc <- uniform_bandit_object_evaluation(visitor_reward=visitorReward,average = TRUE, IsRewardAreBoolean = FALSE,dt.reward=dt.reward)
max(unif_alloc$cum_reg_uniform_bandit_alloc)
### END RANDOM ###
unif_alloc.reward <- reward_cumulative(unif_alloc$uniform_bandit_alloc$choice, visitor_reward = visitorReward)
max(unif_alloc.reward)
#Comparaison
max(my_ctree_ucb.reward_moyenne)
max(my_linucb_ucb.reward_moyenne)
max(my_ctree_ucb.reward_clust)
max(my_linucb_ucb.reward_clust)
###PLOT WITH GGPLOT2 REWARD###
library(ggplot2)
comp_reward <- data.frame(cbind(my_ctree_ucb.reward_moyenne,
my_linucb_ucb.reward_moyenne,
my_ctree_ucb.reward_clust,
my_linucb_ucb.reward_clust,
unif_alloc.reward))
ggplot(comp_reward, aes(c(1:nrow(comp_reward)), y = value, color = Algorithm)) +
geom_line(linetype="dashed",aes(y = my_ctree_ucb.reward_clust, col = "DBACtreeucb"),size = 0.5) +
geom_line(linetype="dashed",aes(y = my_linucb_ucb.reward_clust, col = "DBALinucb"),size = 0.5) +
geom_line(linetype="dashed",aes(y = my_linucb_ucb.reward_moyenne, col = "LinUCB"),size = 1) +
geom_line(linetype="dashed",aes(y = my_ctree_ucb.reward_moyenne, col = "Ctreeucb"),size = 0.5) +
geom_line(linetype="dashed",aes(y = unif_alloc.reward, col = "Uniform"),size = 0.5) +
scale_colour_manual(values =  c("DBACtreeucb"="brown","DBALinucb"="blue","LinUCB"="red","Ctreeucb"="green","Uniform"="black"))+
xlab("Time") +
ylab("Reward")
max(my_linucb_ucb.reward_moyenne)
max(my_linucb_ucb.reward_moyenne)/length(my_linucb_ucb.reward_moyenne)
rm(list=ls())
###Algo 1
fichier <- "cheville_droite_partialDBA191819"
#fichier <- "cheville_droiteDBA191819"
learn=0.3
arm_for_learn = 1
##Chargement du fichier
#please set the directory to this file location
setwd("~/Documents/manue/Manipulation/datascience-emmanuelle/programme_R/serveur_cluster_these/cluster") # the following line is for getting the path of your current open file
current_path <-  getwd()
#source(paste(current_path,'/install_package.R',sep=""))
source(paste(current_path,'/Formating data/R/transform_categorial_to_binary.R',sep=""))
##Définition des variables explicatives
###Data format###
library(jsonlite)
setwd("~/Documents/manue/Manipulation/datascience-emmanuelle/programme_R/serveur_cluster_these/cluster")
df  =  jsonlite::fromJSON(paste(fichier,".JSON",sep=""), simplifyDataFrame = TRUE)  # read text file
#df <-  df [1:10000,]
##A finir
listCategorial =c("clusterV5","clusterV6","clusterV7")
listInteger  = c()
visitorReward <- as.data.frame(transform_categorial_to_binary( listCategorial = c("etat"), dt=df))
for(i in 1:ncol(visitorReward)) visitorReward[,i] <- as.integer(visitorReward[,i])
###
dt <- df[, c(listCategorial,listInteger)]
##Définition des variable explicables
## Algo
##
###File path
(WD <- getwd())
WD <- paste(current_path , "/Bandit", sep = "")
if (!is.null(WD)) setwd(WD)
####CTREE UCB####
#source("R/ctree_object_evaluation.R")
library(bandit4abtest)
for(i in listCategorial) dt[,i] <-as.factor(as.character(dt[,i]))
#Do not multiply the dataset if Config 30_70
#Config 30_70
if(learn==0.3) learn_size = nrow(dt)*0.30
#multiply the dataset if Config 100_100
#Config 100_100
if(learn==0.5) {
learn_size = nrow(dt)
rep_data <- 2
dt <- dt[rep(1:nrow(dt),each=rep_data),]
visitorReward <- visitorReward[rep(1:nrow(visitorReward),each=rep_data),]
}
dt.old <- dt
set.seed(1234)
####CTREEUCBPARAMETER
## - the size of the learning set is a percent of the all dataset nrow(dt)*0.3 or nrow(dt)*0.5
#  - mincriterion parameter refers to 1 -risk error accepted  (0.99,0.95,0.90)
#  - alpha refers to the dynamic allocation parameter (U.C.B)
#  - arm_for_learn is the original varitation (names(visitorReward)[1] or names(visitorReward)[2] ...or  names(visitorReward)[5] )
#  testtype and teststat is refer to type of test to build the tree (see the paper for more details)
# and are not supposed to be modified#
ctreeucb_parameters_control <- ctreeucb_parameters_control_default(dt = dt.old,
visitorReward ,
learn_size = learn_size,
alpha =1,
arm_for_learn = names(visitorReward)[arm_for_learn],
is_reward_are_boolean = TRUE,
ctree_control_val=ctree_control(
mincriterion = 0.95,
testtype = "Bonferroni",
teststat = "quadratic",
splitstat = c( "quadratic"))
)
my_ctree_ucb <- ctreeucbBanditObjectEvaluation(dt= dt.old,visitor_reward=visitorReward, ctree_parameters_control= ctreeucb_parameters_control, average = TRUE)
max(my_ctree_ucb$cum_reg_ctree)
max(my_ctree_ucb$cum_reg_ctree)
###END CTREE UCB###
# transform_categorial_to_binary bug et ca fait chier
dt   <- transform_categorial_to_binary(listCategorial = listCategorial, dt = dt)
dt     <- as.data.frame(dt)
first <- my_ctree_ucb$ctreeucb_bandit_alloc$first_train_element
last <- nrow(dt)
dt <- dt[first:last,]
dt.reward <- dt.old[first:last,]
visitorReward <- visitorReward[first:last,]
my_linucb_ucb <- LinucbBanditObjectEvaluation(dt=dt, visitor_reward=visitorReward, alpha= 1, average = TRUE, IsRewardAreBoolean = TRUE,dt.reward=dt.reward)
max(my_linucb_ucb$cum_reg_linucb)
### END Lin UCB ###
### PLOT  OF REWARD###
my_ctree_ucb.reward_clust <- reward_cumulative(my_ctree_ucb$ctreeucb_bandit_alloc$choice, visitor_reward = visitorReward)
max(my_ctree_ucb.reward_clust)
my_linucb_ucb.reward_clust <- reward_cumulative(my_linucb_ucb$linucb_bandit_alloc$choice, visitor_reward = visitorReward)
max(my_linucb_ucb.reward_clust)
#####################################################################################
################ Moyenne
#####################################################################
######################################################################
###################### A/B Test ########################
rm(list=setdiff(ls(), c("my_ctree_ucb.reward_clust","data.train","my_linucb_ucb.reward_clust","K","fichier","learn","arm_for_learn")))
setwd("~/Documents/manue/Manipulation/datascience-emmanuelle/programme_R/serveur_cluster_these/cluster")
df  =  jsonlite::fromJSON(paste(fichier,".JSON",sep=""), simplifyDataFrame = TRUE)  # read text file
#df <-  df [1:10000,]
##A finir
listCategorial =c()
listInteger  = c("moyenneV5","moyenneV6","moyenneV7")
visitorReward <- as.data.frame(transform_categorial_to_binary( listCategorial = c("etat"), dt=df))
for(i in 1:ncol(visitorReward)) visitorReward[,i] <- as.integer(visitorReward[,i])
###
dt <- df[, c(listInteger)]
##Définition des variable explicables
####CTREE UCB####
#source("R/ctree_object_evaluation.R")
library(bandit4abtest)
#Do not multiply the dataset if Config 30_70
#Config 30_70
if(learn==0.3) learn_size = nrow(dt)*0.30
#multiply the dataset if Config 100_100
#Config 100_100
if(learn==0.5) {
learn_size = nrow(dt)
rep_data <- 2
dt <- dt[rep(1:nrow(dt),each=rep_data),]
visitorReward <- visitorReward[rep(1:nrow(visitorReward),each=rep_data),]
}
dt.old <- dt
set.seed(1234)
####CTREEUCBPARAMETER
## - the size of the learning set is a percent of the all dataset nrow(dt)*0.3 or nrow(dt)*0.5
#  - mincriterion parameter refers to 1 -risk error accepted  (0.99,0.95,0.90)
#  - alpha refers to the dynamic allocation parameter (U.C.B)
#  - arm_for_learn is the original varitation (names(visitorReward)[1] or names(visitorReward)[2] ...or  names(visitorReward)[5] )
#  testtype and teststat is refer to type of test to build the tree (see the paper for more details)
# and are not supposed to be modified#
ctreeucb_parameters_control <- ctreeucb_parameters_control_default(dt = dt.old,
visitorReward ,
learn_size = learn_size,
alpha =1,
arm_for_learn = names(visitorReward)[arm_for_learn ],
is_reward_are_boolean = TRUE,
ctree_control_val=ctree_control(
mincriterion = 0.95,
testtype = "Bonferroni",
teststat = "quadratic",
splitstat = c( "quadratic"))
)
my_ctree_ucb <- ctreeucbBanditObjectEvaluation(dt= dt.old,visitor_reward=visitorReward, ctree_parameters_control= ctreeucb_parameters_control, average = TRUE)
max(my_ctree_ucb$cum_reg_ctree)
max(my_ctree_ucb$cum_reg_ctree)
###END CTREE UCB###
first <- my_ctree_ucb$ctreeucb_bandit_alloc$first_train_element
last <- nrow(dt)
dt <- dt[first:last,]
dt.reward <- dt.old[first:last,]
visitorReward <- visitorReward[first:last,]
my_linucb_ucb <- LinucbBanditObjectEvaluation(dt=dt, visitor_reward=visitorReward, alpha= 1, average = TRUE, IsRewardAreBoolean = TRUE,dt.reward=dt.reward)
max(my_linucb_ucb$cum_reg_linucb)
### END Lin UCB ###
### PLOT  OF REWARD###
my_ctree_ucb.reward_moyenne <- reward_cumulative(my_ctree_ucb$ctreeucb_bandit_alloc$choice, visitor_reward = visitorReward)
max(my_ctree_ucb.reward_moyenne)
my_linucb_ucb.reward_moyenne <- reward_cumulative(my_linucb_ucb$linucb_bandit_alloc$choice, visitor_reward = visitorReward)
max(my_linucb_ucb.reward_moyenne)
### Random ###
unif_alloc <- uniform_bandit_object_evaluation(visitor_reward=visitorReward,average = TRUE, IsRewardAreBoolean = FALSE,dt.reward=dt.reward)
max(unif_alloc$cum_reg_uniform_bandit_alloc)
### END RANDOM ###
unif_alloc.reward <- reward_cumulative(unif_alloc$uniform_bandit_alloc$choice, visitor_reward = visitorReward)
max(unif_alloc.reward)
#Comparaison
max(my_ctree_ucb.reward_moyenne)
max(my_linucb_ucb.reward_moyenne)
max(my_ctree_ucb.reward_clust)
max(my_linucb_ucb.reward_clust)
###PLOT WITH GGPLOT2 REWARD###
library(ggplot2)
comp_reward <- data.frame(cbind(my_ctree_ucb.reward_moyenne,
my_linucb_ucb.reward_moyenne,
my_ctree_ucb.reward_clust,
my_linucb_ucb.reward_clust,
unif_alloc.reward))
ggplot(comp_reward, aes(c(1:nrow(comp_reward)), y = value, color = Algorithm)) +
geom_line(linetype="dashed",aes(y = my_ctree_ucb.reward_clust, col = "DBACtreeucb"),size = 0.5) +
geom_line(linetype="dashed",aes(y = my_linucb_ucb.reward_clust, col = "DBALinucb"),size = 0.5) +
geom_line(linetype="dashed",aes(y = my_linucb_ucb.reward_moyenne, col = "LinUCB"),size = 1) +
geom_line(linetype="dashed",aes(y = my_ctree_ucb.reward_moyenne, col = "Ctreeucb"),size = 0.5) +
geom_line(linetype="dashed",aes(y = unif_alloc.reward, col = "Uniform"),size = 0.5) +
scale_colour_manual(values =  c("DBACtreeucb"="brown","DBALinucb"="blue","LinUCB"="red","Ctreeucb"="green","Uniform"="black"))+
xlab("Time") +
ylab("Reward")
max(my_linucb_ucb.reward_moyenne)
max(my_linucb_ucb.reward_moyenne)/length(my_linucb_ucb.reward_moyenne)
View(df)
set.seed(1234)
####Data generate
temp <- "/home/manue/Documents/manue/données/Transformée/dorcel/BigJoinV2.csv"
temp <- as.data.frame(read.csv2(temp,sep=','))
##Formating
temp$value <-as.numeric( as.character(temp$value) )
temp$langID <- as.factor(temp$langID )
temp <- temp[!is.na(temp$variationID.y),]
###remplace NA in value
temp$value[is.na(temp$value)] <- 0
temp <- unique(temp)
list_col <- c("variationID.y", "visit.y","device","userAgent" ,"name" ,"value")
dt <- temp[,list_col]
summary(as.factor(dt$variationID))
dt <- unique(dt)
##Add test
dt$A <- NA
dt$B <- NA
for(i in 1:nrow(dt)){
if(dt$variationID[i]== 0){ dt$A[i] = dt$value[i]
}else{
dt$B[i] = dt$value[i]
}
}
##### Remplacement en mode mean
library(bandit4abtest)
library(partykit)
#Regression
ctree_models <- c()
#learn on A
ctree_models[[1]] <-  ctree_formula_generate(dt = dt,
visitor_reward = dt[,c("A","B")],
ctree_control_val = ctree_control(teststat = c("quadratic")),
arm_for_learn = "A",
explanatory_variable=  c("visit.y","device","userAgent" ,"name" ),
learn_size = nrow(dt),
print=TRUE)
#learn on B
ctree_models[[2]] <-  ctree_formula_generate(dt = dt,
visitor_reward = dt[,c("A","B")],
ctree_control_val = ctree_control(teststat = c("quadratic")),
arm_for_learn = "B",
explanatory_variable=  c("visit.y","device","userAgent" ,"name" ),
learn_size = nrow(dt),
print=TRUE)
#### Syntetique data ####
dt$A.pred <- NA
dt$B.pred <- NA
dt$A.pred <- predict(ctree_models[[1]],dt)
dt$B.pred <- predict(ctree_models[[2]],dt)
#####################################################################
######################################################################
###################### A/B Test ########################
rm(list=ls()[! ls() %in% c("dt")])
df <- dt
library(bandit4abtest)
library(partykit)
####Configuration
#Conf_30/70
config <- "30_70"
#Conf_100/100
config <- "100_100"
####Configuration
#Conf_30/70
config <- "30_70"
listCategorial =c("name","device","userAgent")
listInteger  = c("visit.y")
#Results for each variation
visitorReward <- df[,c("A.pred","B.pred")]
#Items caracteristics
dt <- df[, c(listCategorial,listInteger)]
set.seed(1234)
if(config  ==  "30_70"  ) learn_size = nrow(dt)*0.30
dt.old <- dt
ctreeucb_parameters_control <- ctreeucb_parameters_control_default(dt = dt.old,
visitorReward ,
learn_size = learn_size,
alpha = 1,
arm_for_learn = names(visitorReward)[1],
is_reward_are_boolean = FALSE,
ctree_control_val=ctree_control(
mincriterion = 0.95,
testtype = "Bonferroni",
teststat = "quadratic",
splitstat = c( "quadratic"))
)
my_ctree_ucb <- ctreeucbBanditObjectEvaluation(dt= dt.old,visitor_reward=visitorReward, ctree_parameters_control= ctreeucb_parameters_control, average = TRUE)
if(config  == "100_100" ){ learn_size = nrow(dt)*1
#### replication ###
rep_data <- 2
dt <- dt[rep(1:nrow(dt),each=rep_data),]
visitorReward <- visitorReward[rep(1:nrow(visitorReward),each=rep_data),]
}
dt.old <- dt
ctreeucb_parameters_control <- ctreeucb_parameters_control_default(dt = dt.old,
visitorReward ,
learn_size = learn_size,
alpha = 1,
arm_for_learn = names(visitorReward)[1],
is_reward_are_boolean = FALSE,
ctree_control_val=ctree_control(
mincriterion = 0.95,
testtype = "Bonferroni",
teststat = "quadratic",
splitstat = c( "quadratic"))
)
my_ctree_ucb <- ctreeucbBanditObjectEvaluation(dt= dt.old,visitor_reward=visitorReward, ctree_parameters_control= ctreeucb_parameters_control, average = TRUE)
library(bandit4abtest)
####Data generate
temp <- "/home/manue/Documents/manue/données/Transformée/dorcel/BigJoinV2.csv"
temp <- as.data.frame(read.csv2(temp,sep=','))
View(temp)
data3 <- temp
save(data3, file = "/home/manue/Documents/manue/GitHub/R-CTree-UCB/bandit4abtest/data/abtest3.rda")
library(bandit4abtest)
temp <- abtest3
temp <- abtest2
library(bandit4abtest)
load("/home/manue/Documents/manue/GitHub/R-CTree-UCB/bandit4abtest/data/abtest3.rda")
View(temp)
githubinstall("bandit4abtest")
library(githubinstall)
githubinstall("bandit4abtest")
