###Si choix réel
# see what kind of result we get
rewards[temp_i] = visitorReward[i,temp_i]
# update the input vector
S <- PlayArm(iter=i,arm=temp_i,S,visitorReward)
proba[temp_i] <-  max(ProbaMaxForUCB(S=S, iter=temp_i, alpha=alpha, K))
temp_i = temp_i +1
}
i=i+1
}
S <- GenerateMatrixS(K)
tic()
#tempo variables
temp_i=1
i=1
###initialisation
while(temp_i<(K+1)){
####Rejection sampling
### le bon choix
if(is.na(visitorReward[i,temp_i])==FALSE){
choice[temp_i] =  temp_i
###Si choix réel
# see what kind of result we get
rewards[temp_i] = visitorReward[i,temp_i]
# update the input vector
S <- PlayArm(iter=i,arm=temp_i,S,visitorReward)
proba[temp_i] <-  max(ProbaMaxForUCB(S=S, iter=temp_i, alpha=alpha, K))
temp_i = temp_i +1
}
i=i+1
}
for(i in i:nrow(visitorReward)){
#    message(S)
choice[i] <- ConditionForUCB(S,iter=temp_i,alpha=alpha,K)
####Rejection sampling
### le bon choix
if(is.na(visitorReward[i,as.integer(choice[i])])==FALSE){
###Si choix réel
# see what kind of result we get
rewards[temp_i] = visitorReward[i,as.integer(choice[i])]
# update the input vector
S <- PlayArm(iter=i,arm=choice[i],S,visitorReward)
proba[i] <-  max(ProbaMaxForUCB(S=S, iter=i, alpha=alpha, K))
temp_i = temp_i +1
}else{
choice[i]= NA
}
}
time <- toc()
options(scipen=999)
#coef estimate
th_hat=S[1,]
#real coef
th = colMeans(visitorReward,na.rm =TRUE)
message("th_hat")
message(th_hat)
message("th real")
message(th)
message(paste('number of used items', sum(ucb_alloc$S[2,1],ucb_alloc$S[2,2])),', number of excludes items :',(nrow(visitorReward) - sum(ucb_alloc$S[2,1],ucb_alloc$S[2,2])), sep= " " )
message(paste('number of used items', sum(S[2,1],S[2,2])),', number of excludes items :',(nrow(visitorReward) - sum(S[2,1],S[2,2])), sep= " " )
message(paste('number of used items', sum(S[2,1],S[2,2])),', number of excluded items :',(nrow(visitorReward) - sum(S[2,1],S[2,2])), sep= " " )
#'UCB_rejection_sampling
#'
#'UCB algorithme with rejection sampling method.
#'Exclud any choices which not corresponds to real exepriments in dataset
#'Stop if something is wrong.
#'Generate a matrix to save the results (S).
#' \itemize{ At each iteration,
#'  \item Calculates the arm probabilities,
#'  \item Choose the arm with the maximum upper bound (with alpha parameter)
#'  \item Receives a reward in visitor_reward for the arm and associated iteration
#'  \item Updates the results matrix S.
#'  }
#'Returns the calculation time.
#'Review the estimated, actual averages and number of choices for each arm.
#'See also \code{\link{ConditionForUCB}}, \code{\link{GenerateMatrixS}},
#'\code{\link{ProbaMaxForUCB}} and \code{\link{PlayArm}}.
#'Require \code{\link{tic}} and \code{\link{toc}} from \code{\link{tictoc}} library
#'@param visitor_reward Dataframe of integer or numeric values
#'@param K Integer value (optional)
#'@param alpha Numeric value (optional)
#'
#'@return
#' \itemize{ List of element:
#'  \item S:numerical matrix of results ,
#'  \item choice: choices of UCB,
#'  \item proba: probability of the chosen arms,
#'  \item time: time of cumputation,
#'  \item theta_hat: mean estimated of each arm
#'  \item theta: real mean of each arm
#'  }
#'
#'@examples
#'## Generates 10000 numbers from 2 binomial  distributions
#'set.seed(4434)
#'K1 <- rbinom(1000, 1, 0.6)
#'K2 <- rbinom(1000, 1, 0.7)
#'## Define a dataframe of rewards
#'visitor_reward <- as.data.frame(cbind(K1,K2) )
#'#remove data
#'temp_list <- sample(1:nrow(visitor_reward), 500, replace = FALSE, prob = NULL)
#'visitor_reward$K1[temp_list] <- NA
#'visitor_reward$K2[-temp_list] <- NA
#'#run ucb on missing data
#'ucb_alloc  <- UCB_rejection_sampling(visitor_reward,alpha = 10)
#'@import tictoc
#'@export
UCB_rejection_sampling <- function(visitorReward, K=ncol(visitorReward) , alpha = 1){
#data formating
visitorReward <- as.matrix(visitorReward)
#keep list of choice
#keep list of choice
choice <- c()
proba <- c()
rewards <- c()
S <- GenerateMatrixS(K)
tic()
#tempo variables
temp_i=1
i=1
###initialisation
while(temp_i<(K+1)){
####Rejection sampling
### le bon choix
if(is.na(visitorReward[i,temp_i])==FALSE){
choice[temp_i] =  temp_i
###Si choix réel
# see what kind of result we get
rewards[temp_i] = visitorReward[i,temp_i]
# update the input vector
S <- PlayArm(iter=i,arm=temp_i,S,visitorReward)
proba[temp_i] <-  max(ProbaMaxForUCB(S=S, iter=temp_i, alpha=alpha, K))
temp_i = temp_i +1
}
i=i+1
}
for(i in i:nrow(visitorReward)){
#    message(S)
choice[i] <- ConditionForUCB(S,iter=temp_i,alpha=alpha,K)
####Rejection sampling
### le bon choix
if(is.na(visitorReward[i,as.integer(choice[i])])==FALSE){
###Si choix réel
# see what kind of result we get
rewards[temp_i] = visitorReward[i,as.integer(choice[i])]
# update the input vector
S <- PlayArm(iter=i,arm=choice[i],S,visitorReward)
proba[i] <-  max(ProbaMaxForUCB(S=S, iter=i, alpha=alpha, K))
temp_i = temp_i +1
}else{
choice[i]= NA
}
}
time <- toc()
options(scipen=999)
#coef estimate
th_hat=S[1,]
#real coef
th = colMeans(visitorReward,na.rm =TRUE)
message("th_hat")
message(th_hat)
message("th real")
message(th)
message(paste('number of used items', sum(S[2,1],S[2,2])),', number of excluded items :',(nrow(visitorReward) - sum(S[2,1],S[2,2])), sep= " " )
return (list('S'=S,'choice'= choice,'proba' = proba,'time'=(time$toc - time$tic),'theta_hat'=th_hat,'theta'=th))
}
?UCB_rejection_sampling
#'UCB_rejection_sampling
#'
#'UCB algorithme with rejection sampling method.
#'Exclud any choices which not corresponds to real exepriments in dataset
#'Stop if something is wrong.
#'Generate a matrix to save the results (S).
#' \itemize{ At each iteration,
#'  \item Calculates the arm probabilities,
#'  \item Choose the arm with the maximum upper bound (with alpha parameter)
#'  \item Receives a reward in visitor_reward for the arm and associated iteration
#'  \item Updates the results matrix S.
#'  }
#'Returns the calculation time.
#'Review the estimated, actual averages and number of choices for each arm.
#'See also \code{\link{ConditionForUCB}}, \code{\link{GenerateMatrixS}},
#'\code{\link{ProbaMaxForUCB}} and \code{\link{PlayArm}}.
#'Require \code{\link{tic}} and \code{\link{toc}} from \code{\link{tictoc}} library
#'@param visitor_reward Dataframe of integer or numeric values
#'@param K Integer value (optional)
#'@param alpha Numeric value (optional)
#'
#'@return
#' \itemize{ List of element:
#'  \item S:numerical matrix of results ,
#'  \item choice: choices of UCB,
#'  \item proba: probability of the chosen arms,
#'  \item time: time of cumputation,
#'  \item theta_hat: mean estimated of each arm
#'  \item theta: real mean of each arm
#'  }
#'
#'@examples
#'## Generates 10000 numbers from 2 binomial  distributions
#'set.seed(4434)
#'K1 <- rbinom(1000, 1, 0.6)
#'K2 <- rbinom(1000, 1, 0.7)
#'## Define a dataframe of rewards
#'visitor_reward <- as.data.frame(cbind(K1,K2) )
#'#remove data
#'temp_list <- sample(1:nrow(visitor_reward), 500, replace = FALSE, prob = NULL)
#'visitor_reward$K1[temp_list] <- NA
#'visitor_reward$K2[-temp_list] <- NA
#'#run ucb on missing data
#'ucb_alloc  <- UCB_rejection_sampling(visitor_reward,alpha = 10)
#'@import tictoc
#'@export
UCB_rejection_sampling <- function(visitorReward, K=ncol(visitorReward) , alpha = 1){
#data formating
visitorReward <- as.matrix(visitorReward)
#keep list of choice
#keep list of choice
choice <- c()
proba <- c()
rewards <- c()
S <- GenerateMatrixS(K)
tic()
#tempo variables
temp_i=1
i=1
###initialisation
while(temp_i<(K+1)){
####Rejection sampling
### le bon choix
if(is.na(visitorReward[i,temp_i])==FALSE){
choice[temp_i] =  temp_i
###Si choix réel
# see what kind of result we get
rewards[temp_i] = visitorReward[i,temp_i]
# update the input vector
S <- PlayArm(iter=i,arm=temp_i,S,visitorReward)
proba[temp_i] <-  max(ProbaMaxForUCB(S=S, iter=temp_i, alpha=alpha, K))
temp_i = temp_i +1
}
i=i+1
}
for(i in i:nrow(visitorReward)){
#    message(S)
choice[i] <- ConditionForUCB(S,iter=temp_i,alpha=alpha,K)
####Rejection sampling
### le bon choix
if(is.na(visitorReward[i,as.integer(choice[i])])==FALSE){
###Si choix réel
# see what kind of result we get
rewards[temp_i] = visitorReward[i,as.integer(choice[i])]
# update the input vector
S <- PlayArm(iter=i,arm=choice[i],S,visitorReward)
proba[i] <-  max(ProbaMaxForUCB(S=S, iter=i, alpha=alpha, K))
temp_i = temp_i +1
}else{
choice[i]= NA
}
}
time <- toc()
options(scipen=999)
#coef estimate
th_hat=S[1,]
#real coef
th = colMeans(visitorReward,na.rm =TRUE)
message("th_hat")
message(th_hat)
message("th real")
message(th)
message(paste('number of used items', sum(S[2,1],S[2,2])),', number of excluded items :',(nrow(visitorReward) - sum(S[2,1],S[2,2])), sep= " " )
return (list('S'=S,'choice'= choice,'proba' = proba,'time'=(time$toc - time$tic),'theta_hat'=th_hat,'theta'=th))
}
ucb_alloc  <- UCB_rejection_sampling(visitorReward, alpha = 1)
ucb_alloc$choice
#'UCB_rejection_sampling
#'
#'UCB algorithme with rejection sampling method.
#'Exclud any choices which not corresponds to real exepriments in dataset
#'Stop if something is wrong.
#'Generate a matrix to save the results (S).
#' \itemize{ At each iteration,
#'  \item Calculates the arm probabilities,
#'  \item Choose the arm with the maximum upper bound (with alpha parameter)
#'  \item Receives a reward in visitor_reward for the arm and associated iteration
#'  \item Updates the results matrix S.
#'  }
#'Returns the calculation time.
#'Review the estimated, actual averages and number of choices for each arm.
#'See also \code{\link{ConditionForUCB}}, \code{\link{GenerateMatrixS}},
#'\code{\link{ProbaMaxForUCB}} and \code{\link{PlayArm}}.
#'Require \code{\link{tic}} and \code{\link{toc}} from \code{\link{tictoc}} library
#'@param visitor_reward Dataframe of integer or numeric values
#'@param K Integer value (optional)
#'@param alpha Numeric value (optional)
#'
#'@return
#' \itemize{ List of element:
#'  \item S:numerical matrix of results ,
#'  \item choice: choices of UCB,
#'  \item proba: probability of the chosen arms,
#'  \item time: time of cumputation,
#'  \item theta_hat: mean estimated of each arm
#'  \item theta: real mean of each arm
#'  }
#'
#'@examples
#'## Generates 10000 numbers from 2 binomial  distributions
#'set.seed(4434)
#'K1 <- rbinom(1000, 1, 0.6)
#'K2 <- rbinom(1000, 1, 0.7)
#'## Define a dataframe of rewards
#'visitor_reward <- as.data.frame(cbind(K1,K2) )
#'#remove data
#'temp_list <- sample(1:nrow(visitor_reward), 500, replace = FALSE, prob = NULL)
#'visitor_reward$K1[temp_list] <- NA
#'visitor_reward$K2[-temp_list] <- NA
#'#run ucb on missing data
#'ucb_alloc  <- UCB_rejection_sampling(visitor_reward,alpha = 10)
#'@import tictoc
#'@export
UCB_rejection_sampling <- function(visitorReward, K=ncol(visitorReward) , alpha = 1){
#data formating
visitorReward <- as.matrix(visitorReward)
#keep list of choice
#keep list of choice
choice <- c()
proba <- c()
rewards <- c()
S <- GenerateMatrixS(K)
tic()
#tempo variables
temp_i=1
i=1
###initialisation
while(temp_i<(K+1)){
####Rejection sampling
### le bon choix
if(is.na(visitorReward[i,temp_i])==FALSE){
choice[i] =  temp_i
###Si choix réel
# see what kind of result we get
rewards[temp_i] = visitorReward[i,temp_i]
# update the input vector
S <- PlayArm(iter=i,arm=temp_i,S,visitorReward)
proba[temp_i] <-  max(ProbaMaxForUCB(S=S, iter=temp_i, alpha=alpha, K))
temp_i = temp_i +1
}else{
choice[i] = NA
}
i=i+1
}
for(i in i:nrow(visitorReward)){
#    message(S)
choice[i] <- ConditionForUCB(S,iter=temp_i,alpha=alpha,K)
####Rejection sampling
### le bon choix
if(is.na(visitorReward[i,as.integer(choice[i])])==FALSE){
###Si choix réel
# see what kind of result we get
rewards[temp_i] = visitorReward[i,as.integer(choice[i])]
# update the input vector
S <- PlayArm(iter=i,arm=choice[i],S,visitorReward)
proba[i] <-  max(ProbaMaxForUCB(S=S, iter=i, alpha=alpha, K))
temp_i = temp_i +1
}else{
choice[i]= NA
}
}
time <- toc()
options(scipen=999)
#coef estimate
th_hat=S[1,]
#real coef
th = colMeans(visitorReward,na.rm =TRUE)
message("th_hat")
message(th_hat)
message("th real")
message(th)
message(paste('number of used items', sum(S[2,1],S[2,2])),', number of excluded items :',(nrow(visitorReward) - sum(S[2,1],S[2,2])), sep= " " )
return (list('S'=S,'choice'= choice,'proba' = proba,'time'=(time$toc - time$tic),'theta_hat'=th_hat,'theta'=th))
}
ucb_alloc  <- UCB_rejection_sampling(visitorReward, alpha = 1)
ucb_alloc$choice
## Generates 10000 numbers from 2 binomial  distributions
set.seed(4434)
K1 <- rbinom(1000, 1, 0.6)
K2 <- rbinom(1000, 1, 0.7)
## Define a dataframe of rewards
visitor_reward <- as.data.frame(cbind(K1,K2) )
#remove data
temp_list <- sample(1:nrow(visitor_reward), 500, replace = FALSE, prob = NULL)
visitor_reward$K1[temp_list] <- NA
visitor_reward$K2[-temp_list] <- NA
#run ucb on missing data
ucb_alloc  <- UCB_rejection_sampling(visitor_reward,alpha = 10)
ucb_rejection_sampling_alloc  <- UCB_rejection_sampling(visitor_reward,alpha = 10)
K=ncol(visitor_reward)
alpha=1
ucb_rejection_sampling_bandit_alloc <- UCB_rejection_sampling(visitor_reward, alpha = alpha, K=K)
cum_rew_ucb_rejection_sampling_alloc <- reward_cumulative(choice=choice,visitor_reward=visitor_reward)
cum_rew_ucb_rejection_sampling_alloc <- reward_cumulative(choice=ucb_rejection_sampling_bandit_alloc$choice,visitor_reward=visitor_reward)
ucb_rejection_sampling_bandit_alloc <- UCB_rejection_sampling(visitor_reward, alpha = alpha, K=K)
cum_rew_ucb_rejection_sampling_alloc <- reward_cumulative(choice=ucb_rejection_sampling_bandit_alloc$choice,visitor_reward=visitor_reward)
anyNA(ucb_rejection_sampling_bandit_alloc$choice)
#'Return list of cumulative reward
#'
#'Return a list with cumulative rewards at each iterations. Can be used for rejection samplig method.
#'
#'@param choice  Integer list
#'@param visitor_reward dataframe of integer or numeric values
#'
#'@return List of numeric values
#'
#'@examples
#'##### Pairewise #####
#'set.seed(1234)
#'size.tot <- 10000
#'x <- seq(0, 5, 0.01)
#'x1<- sample(x, size.tot, replace = TRUE, prob = NULL)
#'arm_1 <-  as.vector(c(2,-1,1.5,0))
#'K1 <- (x1 < 1 ) * arm_1[4]  +
#'  (x1 >= 1 & x1 < 2 ) * arm_1[1]  +
#'  (x1 >= 2 & x1 < 3) * arm_1[2]  +
#'  (x1 >= 3 & x1 < 4) * arm_1[3]  +
#'  (x1 >= 4) * arm_1[4]
#'plot(x1, K1)
#'
#'arm_2 <-  as.vector(c(1.5,-0.5,1.25,0))
#'K2 <- (x1 < 1 ) * arm_2[4]  +
#'  (x1 >= 1 & x1 < 2 ) * arm_2[1]  +
#'  (x1 >= 2 & x1 < 3) * arm_2[2]  +
#'  (x1 >= 3 & x1 < 4) * arm_2[3]  +
#'  (x1 >= 4) * arm_2[4]
#'plot(x1, K2)
#'#covariate without interest
#'x2<- sample(x, size.tot, replace = TRUE, prob = NULL)
#'#Results for each variation
#'visitor_reward <-  data.frame(K1,K2 )
#'summary(visitor_reward)
#'dt <- as.data.frame(cbind(x1,x2))
#'#Random choices
#'choice <- sample(c(1,2), size.tot, replace = TRUE)
#'reward <- reward_cumulative(choice=choice,visitor_reward=visitor_reward)
#'plot(1:size.tot,  cumsum(reward))
#'@export
reward_cumulative <- function(choice, visitor_reward){
if(anyNA(choice)==FALSE){
reward.evolutive <- c()
for(i in 1:nrow(visitor_reward)) reward.evolutive[i] <- visitor_reward[i,choice[i]]
return(cumsum(reward.evolutive))
}else{
reward.evolutive <- c()
j=1
for(i in 1:nrow(visitor_reward)){
if(is.na(choice[i])==FALSE){
reward.evolutive[j] <- visitor_reward[i,choice[i]]
j=j+1
}
}
return(cumsum(reward.evolutive))
}
}
cum_rew_ucb_rejection_sampling_alloc <- reward_cumulative(choice=ucb_rejection_sampling_bandit_alloc$choice,
visitor_reward=visitor_reward)
if(average == TRUE) cum_reg_ucb_bandit_alloc <- cumulativeRegretAverage(ucb_bandit_alloc$choice,
visitor_reward = visitor_reward,
dt=dt.reward,
IsRewardAreBoolean=IsRewardAreBoolean,
explanatory_variable=explanatory_variable)
cum_rew_ucb_rejection_sampling_alloc <- reward_cumulative(choice=ucb_rejection_sampling_bandit_alloc$choice,
visitor_reward=visitor_reward)
cum_rew_ucb_rejection_sampling_alloc <- reward_cumulative(choice=ucb_rejection_sampling_bandit_alloc$choice,
visitor_reward=visitor_reward)
cum_rew_ucb_rejection_sampling_alloc
plot(cum_rew_ucb_rejection_sampling_alloc)
plot(cum_rew_ucb_rejection_sampling_alloc, type = 'l')
max(cum_rew_ucb_rejection_sampling_alloc)/length(cum_rew_ucb_rejection_sampling_alloc)
message(paste("average : "),max(cum_rew_ucb_rejection_sampling_alloc)/length(cum_rew_ucb_rejection_sampling_alloc), sep = " " )
library(bandit4abtest)
?plot
plot(cum_rew_ucb_rejection_sampling_alloc, type = 'l',xlab = "Ucb Rejection Sampling")
plot(cum_rew_ucb_rejection_sampling_alloc, type = 'l',ylab = "Ucb Rejection Sampling")
#################
rm(list = ls())
#Contextual with continus reward
size.tot = 10000
set.seed(4649)                          # this makes the example exactly reproducible
x1 = runif(size.tot, min=0, max=10)          # you have 2, largely uncorrelated predictors
x2 = runif(size.tot, min=0, max=10)
dt = cbind(x1,x2)
#arm reward
arm_1 <-  as.vector(c(0,0.5))
K1 = crossprod(t(dt),arm_1) + runif(size.tot, min=-1, max=1)    #  linear predictor
summary(K1)
arm_2 <-  as.vector(c(0.5,0))
K2 = crossprod(t(dt),arm_2) + runif(size.tot, min=-1, max=1)
summary(K2)
visitor_reward <-  data.frame(K1,K2)
dt <- as.data.frame(dt)
linucb_contextual_alloc <- LINUCB(dt,visitor_reward )
cum_reg_linucb_contextual_alloc <- cumulativeRegretAverage(linucb_contextual_alloc$choice,visitor_reward,dt = dt)
K1 = crossprod(t(dt),arm_1)     #  linear predictor
summary(K1)
arm_2 <-  as.vector(c(0.5,0))
K2 = crossprod(t(dt),arm_2)
summary(K2)
visitor_reward <-  data.frame(K1,K2)
dt <- as.data.frame(dt)
linucb_contextual_alloc <- LINUCB(dt,visitor_reward )
cum_reg_linucb_contextual_alloc <- cumulativeRegretAverage(linucb_contextual_alloc$choice,visitor_reward,dt = dt)
?UCB
?EpsilonGreedy
